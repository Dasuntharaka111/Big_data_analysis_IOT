# Big_data_analysis_IOT

Step 1: Hadoop runs using Docker
![Screenshot 2025-04-28 165017](https://github.com/user-attachments/assets/b096a10d-8660-47ae-ba87-c83ed889773c)

Step 2: Make an input Directory
![2](https://github.com/user-attachments/assets/509690bd-c21d-46cc-b390-639942524f02)

Step 3: Move the Sales.csv file into the Docker container
![3](https://github.com/user-attachments/assets/05091456-5de4-4586-b82e-519bb3d429f8)
![4](https://github.com/user-attachments/assets/41aafc9a-52bc-4c0b-9948-6d9818765501)

Step 4: Check HDFS
![5](https://github.com/user-attachments/assets/71edfce7-b047-499c-a74e-5e2537bd62cc)

Step 5: MapReduce Java

Step 6: Compile and Run the Map Reduce
![7](https://github.com/user-attachments/assets/31c152b3-f5d0-4284-b949-eb063bfbf896)

Output:
![final](https://github.com/user-attachments/assets/af4b31b6-6998-4c39-9c91-fd5deafd68fe)
